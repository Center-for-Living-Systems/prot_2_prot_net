{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65f10a-db16-448e-8553-58f4cd29d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from itertools import product as iterprod\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from argparse import ArgumentParser\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import utils.data_processing as dp\n",
    "from utils.UNeXt import UNet\n",
    "from utils.loss import loss_function_dict\n",
    "\n",
    "import utils.nb_utils as nb_utils\n",
    "\n",
    "import pprint\n",
    "\n",
    "np.random.seed(11) # for reproducibility\n",
    "torch.manual_seed(11)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67c512-d865-4787-8900-b37ff14815ef",
   "metadata": {},
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f48878-9c77-4a04-8ec6-0186ae33dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 8\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pin_memory = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Dataset\n",
    "directory  = './data/ZyxAct_16kPa_small/'\n",
    "test_cells = 'cell_1'\n",
    "\n",
    "\n",
    "in_channels  = [[6],[7]] # Example: [[4], [4,6], [4,6,7]]. Channel 4 is mask, 6 is zyxin, 7 is other protein (here actin)\n",
    "out_channels = (2,3)\n",
    "transform_kwargs = {'crop_size': 512,\n",
    "                    'output_channels': out_channels, \n",
    "                    'vector_components': [out_channels, (0,1)],\n",
    "                    'magnitude_only': False,\n",
    "                    'angmag': True,\n",
    "                    'norm_output': {'rescale': 0.25, 'threshold': 0.4},\n",
    "                    }\n",
    "\n",
    "dataset_kwargs = { \n",
    "                    'root': directory,\n",
    "                    'force_load': False,\n",
    "                    'test_split': 'bycell',\n",
    "                    'test_cells': test_cells,\n",
    "                    'in_channels': in_channels, \n",
    "                    'out_channels': out_channels, \n",
    "                    'transform_kwargs': transform_kwargs,\n",
    "                    'frames_to_keep': 256,\n",
    "                    'input_baseline_normalization': 'outside_inside', # Comment on what these do\n",
    "                    'output_baseline_normalization': 'mean_dataset',\n",
    "                    'remake_dataset_csv': True,\n",
    "                    'exclude_frames': [31,90]\n",
    "                     }\n",
    "\n",
    "\n",
    "dataset = dp.CellDataset( **dataset_kwargs )\n",
    "\n",
    "train_loader = dataset.get_loader(dataset.train_indices, batch_size, num_workers, pin_memory)\n",
    "validation_loader = dataset.get_loader(dataset.test_indices, batch_size, num_workers, pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b1c80-bb7d-441b-822d-8c92a5b37a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581858f1-cca6-4649-8e6d-03fee559b2a2",
   "metadata": {},
   "source": [
    "# Some visualizations of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edcedc-9178-41e8-9e7c-0cf1a52ecc15",
   "metadata": {},
   "source": [
    "The dataset class gets items by looking into a dataframe (`dataset.info`) where the folders and filenames are stored. Folders correspond to single cells, and each file is a frame of the time series. \n",
    "\n",
    "`dataset.info` contains the normalization values which the data is normalized by before it is passed to the NN. Forces are normalized by `dataset.info.F_mean` and the zyxin signal is normalized by `dataset.info.zyxin_baseline_out` and `dataset.info.zyxin_baseline_in`. Details about how these are generated can be found in the DataProcessing notebook.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284c667-83dc-4ac8-b6c9-dcd3045a0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.info.copy()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7016587-df03-44d5-9513-77d87d1d9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test cells: \n",
    "print(dataset.test_cells)\n",
    "print(dataset.test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d08ed-5565-4df1-b023-56588e5838dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,3,figsize=(2*3, 2*2), dpi=144)\n",
    "\n",
    "cell = 'cell_1'\n",
    "frame = 5\n",
    "\n",
    "idx = dataset.info.index[(dataset.info.folder==cell)&(dataset.info.frame==frame)].tolist()[0] # Get index in dataframe that contains the right cell and frame.\n",
    "\n",
    "sample = dataset[idx] # get item\n",
    "\n",
    "print({key: sample[key].shape for key in sample.keys()})\n",
    "\n",
    "\n",
    "ax[0][0].set_title('Mask')\n",
    "ax[0][0].imshow(sample['mask'].squeeze(), origin='lower', cmap='gray', vmax=1, vmin=0)\n",
    "ax[0][1].set_title('Zyxin')\n",
    "ax[0][1].imshow(sample['zyxin'].squeeze(), origin='lower', cmap='gray', vmax=3, vmin=0)\n",
    "ax[0][2].set_title('Actin')\n",
    "ax[0][2].imshow(sample['actin'].squeeze(), origin='lower', cmap='gray', vmax=10, vmin=0)\n",
    "\n",
    "ax[1][0].set_title('$|F|$')\n",
    "ax[1][0].imshow(sample['output'].squeeze()[0], origin='lower', cmap='inferno')\n",
    "ax[1][1].set_title('Force angle $\\\\alpha$')\n",
    "ax[1][1].imshow(sample['output'].squeeze()[1], origin='lower', vmax=np.pi, vmin=-np.pi)\n",
    "ax[1][2].set_title('$\\\\vec{F}$')\n",
    "ax[1][2].imshow(sample['output'].squeeze()[0], origin='lower', cmap='inferno')\n",
    "ax[1][2].quiver(*nb_utils.make_vector_field(*sample['output'].squeeze(), downsample=15, threshold=0.4, angmag=True), color='w', scale=20)\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b32dd-e961-4f1a-a51f-2fb221d717fd",
   "metadata": {},
   "source": [
    "# Build U-Net model with ConvNext blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e8420-e504-48b3-9c28-ca0243e2e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lyr  = 3 # number of downsampling layers\n",
    "ds_krnl= 4 # downsample kernel\n",
    "n_ch   = 4 # number of channels in the beginning of the network\n",
    "n_blocks = 4 # number of ConvNext blocks, wherever ConvNext blocks are used\n",
    "\n",
    "prepend_hparams = {'start_channel': 1, 'resnet_channel': n_ch, 'end_channel': n_ch, 'N_blocks': n_blocks,                                         # Args for architecture\n",
    "                    'kernel': 7,'stride': 1, 'inv_bottleneck_factor': 4, 'dilation': 1,'dropout_rate': 0.1, 'activation': 'gelu', 'batchnorm': 1} # Args for ConvNext blocks\n",
    "encoder_hparams = {'n_ch': n_ch, 'n_layers': n_lyr, 'N_node_blocks': n_blocks, 'N_skip_blocks': n_blocks,\n",
    "                    'downsample_kwargs': {'kernel': ds_krnl, 'activation': 'gelu', 'batchnorm': 1},\n",
    "                    'interlayer_kwargs': {'kernel': 7,'stride': 1, 'inv_bottleneck_factor': 4, 'dilation': 1,'dropout_rate': 0.1, 'activation': 'gelu', 'batchnorm': 1}\n",
    "                    }\n",
    "decoder_hparams = {'n_layers': n_lyr, 'N_node_blocks': n_blocks, 'upsample_kernel': ds_krnl,\n",
    "                    'kernel': 7,'stride': 1, 'inv_bottleneck_factor': 4, 'dilation': 1,'dropout_rate': 0.1, 'activation': 'gelu', 'batchnorm': 1}\n",
    "append_hparams = {'start_channel': n_ch, 'resnet_channel': n_ch, 'end_channel': 2, 'N_blocks': n_blocks,\n",
    "                    'kernel': 7,'stride': 1, 'inv_bottleneck_factor': 8, 'dilation': 1,'dropout_rate': 0.1, 'activation': 'gelu', 'batchnorm': 1} \n",
    "optimizer_hparams = {'LR': 0.001, 'schedule_rate': 0.99}\n",
    "loss_hparams = {'loss_type': 'am',\n",
    "                'exp_weight': 0.0,\n",
    "                'strainenergy_regularization': 0.0,\n",
    "                'exp_schedule': {'type': 'linear', 'width': 310, 'e_crit': 30},\n",
    "                'reg_schedule': {'type': 'linear', 'width': 310, 'e_crit': 30},\n",
    "                'loss_kwargs': {'max_force': 8.}\n",
    "               }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = {}\n",
    "for protein in ['zyxin', 'actin']:\n",
    "    modelname = 'model_0'\n",
    "\n",
    "    logger_params = {'log_dir': f'./tensorboard_logs/{modelname}', \n",
    "                     'image_epoch_freq': 10,\n",
    "                     'image_callbacks': 'vectorfield,hists',\n",
    "                     'save_model_freq': 20}\n",
    "\n",
    "    # Actually build model:\n",
    "    model_kwargs={\n",
    "                    'input_type':  protein, \n",
    "                    'prepend_hparams': prepend_hparams, \n",
    "                    'encoder_hparams': encoder_hparams, \n",
    "                    'decoder_hparams': decoder_hparams, \n",
    "                    'append_hparams': append_hparams, \n",
    "                    'optimizer_hparams': optimizer_hparams,\n",
    "                    'loss_hparams': loss_hparams,\n",
    "                    'logger_params': logger_params,\n",
    "                    'name': 'model_0'}\n",
    "\n",
    "\n",
    "    model = UNet( **model_kwargs, model_idx=0)\n",
    "    model.to(device)\n",
    "    \n",
    "    models[protein] = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc7152-01e6-4c50-8a76-f2670773a025",
   "metadata": {},
   "source": [
    "# Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed690a77-055d-46df-931a-75d67f606fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models = False\n",
    "n_epochs = 150\n",
    "\n",
    "pbar = tqdm(total=n_epochs*(np.minimum(dataset.frames_to_keep, len(dataset.train_indices))/batch_size))\n",
    "\n",
    "t0 = time.time()\n",
    "for e in range(n_epochs):\n",
    "    pbar.set_description(f'Epoch {e}')\n",
    "    loss_values_train = {}\n",
    "    loss_values_val = {}\n",
    "\n",
    "    for mkey in models.keys():\n",
    "        models[mkey].reset_running_train_loss()\n",
    "        models[mkey].reset_running_val_loss()\n",
    "\n",
    "    for sample in train_loader: \n",
    "        for key in sample:\n",
    "            sample[key] = sample[key].to(device)\n",
    "        \n",
    "        for mkey in models.keys():\n",
    "            models[mkey].training_step(sample, epoch=e) # loss.backward() and optimizer step occur in here\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "    for sample in validation_loader:\n",
    "        for key in sample:\n",
    "            sample[key] = sample[key].to(device)\n",
    "    \n",
    "        for mkey in models.keys():\n",
    "            models[mkey].validation_step(sample, epoch=e)\n",
    "\n",
    "    for mkey in models.keys():\n",
    "        models[mkey].scheduler.step()\n",
    "\n",
    "    print(\"Epoch %u:\\t Time: %0.2f \\t(per epoch: %0.2f)\"%(e, time.time()-t0, (time.time()-t0)/(e+1)))\n",
    "\n",
    "    # SAVE\n",
    "    if save_models:\n",
    "        # Log in tensorboard\n",
    "        for mkey in models.keys():\n",
    "            model[mkey].log_images(epoch=e)\n",
    "            model[mkey].log_scalars(epoch=e) \n",
    "            \n",
    "        # Save models\n",
    "        if e%(logger_params['save_model_freq'])==0 or e==n_epochs-1: \n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'model_kwargs': model_kwargs,\n",
    "                        'model_name': model.name,\n",
    "                        'model_idx': model.index,\n",
    "                        'dataset_kwargs': dataset_kwargs,\n",
    "                        'test_cells': dataset.test_cells,\n",
    "                        }, \n",
    "                       os.path.join( model.logdir, 'model.pt') )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0a343-64ea-4f12-b07d-0dd9da32884c",
   "metadata": {},
   "source": [
    "# Plot prediction on train cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3857c-e082-4687-b306-6468aa1b4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(3*3, 3*1), dpi=200)\n",
    "\n",
    "model = models['actin']\n",
    "\n",
    "eval_dataset_kwargs = dataset_kwargs\n",
    "eval_dataset_kwargs['transform_kwargs']['crop_size'] = 960\n",
    "eval_dataset_kwargs['exclude_frames'] = None\n",
    "dataset_eval = dp.CellDataset( **eval_dataset_kwargs )\n",
    "\n",
    "cell = 'cell_3'\n",
    "frame = 0\n",
    "\n",
    "idx = dataset_eval.info.index[(dataset_eval.info.folder==cell)&(dataset_eval.info.frame==frame)].tolist()[0] # Get index in dataframe that contains the right cell and frame.\n",
    "\n",
    "\n",
    "sample = dataset_eval[idx] # get item\n",
    "\n",
    "input_image = model.select_inputs(model.input_type, sample).unsqueeze(0).to(device)\n",
    "print(input_image.shape)\n",
    "\n",
    "pred = model(input_image).detach().cpu().numpy()\n",
    "\n",
    "print(pred.shape)\n",
    "\n",
    "ax[0].set_title('Zyxin')\n",
    "ax[0].imshow(sample['zyxin'].squeeze(), origin='lower', cmap='gray', vmax=3, vmin=0)\n",
    "\n",
    "ax[1].set_title('$\\\\vec{F}_{exp}$')\n",
    "ax[1].imshow(sample['output'].squeeze()[0], origin='lower', cmap='inferno', vmax=4, vmin=0)\n",
    "ax[1].quiver(*nb_utils.make_vector_field(*sample['output'].squeeze(), downsample=20, threshold=0.4, angmag=True), color='w', scale=20, width=0.003)\n",
    "\n",
    "ax[2].set_title('$\\\\vec{F}_{NN}$')\n",
    "ax[2].imshow(pred.squeeze()[0], origin='lower', cmap='inferno', vmax=4, vmin=0)\n",
    "ax[2].quiver(*nb_utils.make_vector_field(*pred.squeeze(), downsample=20, threshold=0.4, angmag=True), color='w', scale=20, width=0.003)\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d2b03-ccd3-483c-9b08-3ed8b9dfa3ef",
   "metadata": {},
   "source": [
    "# Performance on test cell\n",
    "## It seems to underpredict quite dramatically, but we don't necessarily expect great generalization because the network was trained on an extremely small dataset (~180 frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14c315-a324-497d-a841-8d52851e74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(3*3, 3*1), dpi=200)\n",
    "\n",
    "model = models['actin']\n",
    "\n",
    "eval_dataset_kwargs = dataset_kwargs\n",
    "eval_dataset_kwargs['transform_kwargs']['crop_size'] = 960\n",
    "eval_dataset_kwargs['exclude_frames'] = None\n",
    "dataset_eval = dp.CellDataset( **eval_dataset_kwargs )\n",
    "\n",
    "cell = 'cell_1'\n",
    "frame = 100\n",
    "\n",
    "idx = dataset_eval.info.index[(dataset_eval.info.folder==cell)&(dataset_eval.info.frame==frame)].tolist()[0] # Get index in dataframe that contains the right cell and frame.\n",
    "\n",
    "\n",
    "sample = dataset_eval[idx] # get item\n",
    "\n",
    "input_image = model.select_inputs(model.input_type, sample).unsqueeze(0).to(device)\n",
    "print(input_image.shape)\n",
    "\n",
    "pred = model(input_image).detach().cpu().numpy()\n",
    "\n",
    "print(pred.shape)\n",
    "\n",
    "ax[0].set_title('Zyxin')\n",
    "ax[0].imshow(sample['zyxin'].squeeze(), origin='lower', cmap='gray', vmax=3, vmin=0)\n",
    "\n",
    "ax[1].set_title('$\\\\vec{F}_{exp}$')\n",
    "ax[1].imshow(sample['output'].squeeze()[0], origin='lower', cmap='inferno', vmax=4, vmin=0)\n",
    "ax[1].quiver(*nb_utils.make_vector_field(*sample['output'].squeeze(), downsample=20, threshold=0.4, angmag=True), color='w', scale=20, width=0.003)\n",
    "\n",
    "ax[2].set_title('$\\\\vec{F}_{NN}$')\n",
    "ax[2].imshow(pred.squeeze()[0], origin='lower', cmap='inferno', vmax=4, vmin=0)\n",
    "ax[2].quiver(*nb_utils.make_vector_field(*pred.squeeze(), downsample=20, threshold=0.4, angmag=True), color='w', scale=20, width=0.003)\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b951ae-56cc-4e4e-8ee2-9bac6cda992c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
